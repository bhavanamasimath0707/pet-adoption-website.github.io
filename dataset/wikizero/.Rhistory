x0 = c(rep(1,5),rep(2,5),rep(3,5),rep(4,5),rep(5,5))
View(x0)
plot(x0, y0)
zero.res = lmodel2(y0 ~ x0, data=Ex6, "relative", "relative")
Ex6 = as.data.frame(cbind(x0,y0))
zero.res = lmodel2(y0 ~ x0, data=Ex6, "relative", "relative")
print(zero.res)
op <- par(mfrow = c(1,2))
plot(zero.res, "OLS")
plot(zero.res, "MA")
par(op)
t.test(x, alternative = "less", mu = 10)
t.test(Ex6, alternative = "less", mu = 10)
#Is there evidence that the "mean level" of Salmonella in the ice cream is "greater than 0.3 MPN/g?"
#H0:  mu = 0.3  Ha:  mu > 0.3
x = c(0.593, 0.142, 0.329, 0.691, 0.231, 0.793, 0.519, 0.392, 0.418)
t.test(x, alternative="greater", mu=0.3)
Control = c(91, 87, 99, 77, 88, 91)
Treat = c(101, 110, 103, 93, 99, 104)
t.test(Control,Treat,alternative="less", var.equal=TRUE) # assuming equal standard deviation
t.test(Control,Treat,alternative="less") #not assuming equal standard deviation
reg = c(16, 20, 21, 22, 23, 22, 27, 25, 27, 28)
prem = c(19, 22, 24, 24, 25, 25, 26, 26, 28, 32)
t.test(prem,reg,alternative="greater", paired=TRUE)
attach(InsectSprays)
str(InsectSprays)
tapply(count, spray, mean)
tapply((count, spray,var)
tapply(count, spray,var)
tapply(count, spray, length)
boxplot(count~spray)
View(InsectSprays)
Photoperiod <- ordered(spray,levels=c("F","B","C","D","E","A"))
tapply(count,Photoperiod,mean)
tapply(count, spray, mean)
is.factor(spray)
is.factor(Photoperiod)
is.factor(spray)
#oneway test
oneway.test(count~spray)
#aov
aov.out = aov(count ~ spray, data=InsectSprays)
summary(InsectSprays)
summary(aov.out)
#POST-HOC TEST
#tukeyhsd()
TukeyHSD(aov.out)
summary.lm(aov.out)
#homogenity of variance
bartlett.test(count ~ spray, data=InsectSprays)
plot(aov.out)
#non-parametric alternative to anova
kruskal.test(count ~ spray, data=InsectSprays)
#attach ın başka versiyonu
with(PlantGrowth, tapply(weight, group, mean))
with(PlantGrowth, tapply(weight, group, var))
str(PlantGrowth)
with(PlantGrowth, bartlett.test(weight ~ group))
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(PlantGrowth, lm(weight ~ group))
summary(lm.out)
summary.aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(results)
results <- summary.aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(results)
TukeyHSD(lm.out)
TukeyHSD(aov.out)
aov.out <- summary.aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(aov.out)
aov.out <- aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(aov.out)
library("httr", lib.loc="~/R/win-library/3.5")
library("XML", lib.loc="~/R/win-library/3.5")
library("dplyr", lib.loc="~/R/win-library/3.5")
library("ggplot2", lib.loc="~/R/win-library/3.5")
library("MASS", lib.loc="~/R/win-library/3.5")
library("MASS", lib.loc="C:/Program Files/R/R-3.5.2/library")
attach(PlantGrowth)
View(PlantGrowth)
with(PlantGrowth, tapply(weight, group, mean))
with(PlantGrowth, tapply(weight, group, var))
with(PlantGrowth, bartlett.test(weight ~ group))
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(PlantGrowth, lm(weight ~ group))
summary(lm.out)
###There is a difference, but where does this difference lie? Post Hoc test:
aov.out <- aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(aov.out)
with(PlantGrowth, tapply(weight, group, mean))
with(PlantGrowth, tapply(weight, group, var))
#homogenity of variance #test assumptions
bartlett.test(count ~ spray, data=InsectSprays)
with(PlantGrowth, bartlett.test(weight ~ group))
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(PlantGrowth, lm(weight ~ group))
summary(lm.out)
###There is a difference, but where does this difference lie? Post Hoc test:
aov.out <- aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(aov.out)
x <- c(237,289,257,228,303,275,262,304,244,233)
y <- c(194,240,230,186,265,222,242,281,240,212)
d <- c(43,49,27,42,38,53,20,23,4,21)
shapiro.test(d)
x <- c(237,289,257,228,303,275,262,304,244,233)
shapiro.test(x)
shapiro.test(y)
t.test(x,y,alternative="less",paired=TRUE)
t.test(d,alternative="less",paired=TRUE)
t.test(x,y,,alternative="less",paired=TRUE)
t.test(x,y,,alternative="greater",paired=TRUE)
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(PlantGrowth, lm(weight ~ group))
TukeyHSD(lm.out)
drug <- c(x,y)
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(drug, lm(x ~ y))
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(d, lm(x ~ y))
TukeyHSD(d)
drug <- c("x","y")
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(drug, lm(x ~ y))
drug <- data.frame(x,y)
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(drug, lm(x ~ y))
###There is a difference, but where does this difference lie? Post Hoc test:
aov.out <- aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(d)
TukeyHSD(drug)
TukeyHSD(lm.out)
TukeyHSD(aov.out)
x <- c(237,289,257,228,303,275,262,304,244,233)
y <- c(194,240,230,186,265,222,242,281,240,212)
d <- c(43,49,27,42,38,53,20,23,4,21)
groups <- c(rep(1,10),rep(2,10))
drug <- data.frame(x,y)
set <- c(x,y,d)
out <- aov(drug~as.factor(groups),data = set)
View(drug)
drug <- data.frame(x,y,d)
with(drug, bartlett.test(x ~ y))
chisq.test(x,y)
t.test(x,y,paired = TRUE,var.equal = TRUE,alternative = c("greater"))
source('C:/Users/user/ucuncu_sinif/sc/final/hypo_test.R', echo=TRUE)
t.test(x,y,paired = TRUE,var.equal = TRUE,alternative = c("two.sided"))
greater
t.test(x,y,paired = TRUE,var.equal = TRUE,alternative = c("greater"))
t.test(x,y,paired = TRUE,var.equal = TRUE,alternative = c("greater"))
t.test(x,y,paired = TRUE,var.equal = TRUE,alternative = c("greater"))
var.test(x,y)
t=read.csv("w.csv")
Location=t$Location
#Finding the count of "NA" values within each feature of the dataset
count= sort(sapply(t, function(y) sum(length(which(is.na(y))))))
#Percentage of "NA" values within each feature of the dataset
countpercent=sapply(t, function(y) round(sum(length(which(is.na(y))))/nrow(t)*100))
#Extracting name of features - having "NA" values more than 1/3 of its number of observations
na_count=which(count>nrow(t)/3)
names=names(na_count)
par(mar=c(5,5.3,4,2))
t=t %>% select(-RISK_MM,-Date,-Location,-names)
#Finding the count of "NA" values within each feature of the dataset.
count2=sapply(t, function(y) sum(length(which(is.na(y)))))
#Percentage of "NA" values within each feature
count2percent=sort(sapply(t, function(y) round(sum(length(which(is.na(y))))/nrow(t)*100)))
t$RainToday <- ifelse(t$RainToday=="Yes", 1, 0)
t$RainToday= factor(t$RainToday)
t$RainTomorrow <- ifelse(t$RainTomorrow=="Yes", 1, 0)
t$RainTomorrow=factor(t$RainTomorrow)
registerDoParallel(cores = 14)
getDoParWorkers()
library(naniar)
library(missRanger)
library(doParallel)
library(ggplot2)
library(tidyverse)
library(onehot)
library(data.table)
library(mltools)
library(caret)
library(car)
library(dplyr)
library(ggplot2)
require(xgboost)
library(DiagrammeR)
library(rpart)
library(rpart.plot)
library(corrplot)
library(VIM)
library(randomForest)
library(ggplot2)
library(graphics)
t=t %>% select(-RISK_MM,-Date,-Location,-names)
#Finding the count of "NA" values within each feature of the dataset.
count2=sapply(t, function(y) sum(length(which(is.na(y)))))
#Percentage of "NA" values within each feature
count2percent=sort(sapply(t, function(y) round(sum(length(which(is.na(y))))/nrow(t)*100)))
t$RainToday <- ifelse(t$RainToday=="Yes", 1, 0)
t$RainToday= factor(t$RainToday)
t$RainTomorrow <- ifelse(t$RainTomorrow=="Yes", 1, 0)
t$RainTomorrow=factor(t$RainTomorrow)
registerDoParallel(cores = 14)
getDoParWorkers()
Weather_Imp_t <- missRanger(t, pmm.k = 3, splitrule = "extratrees", num.trees = 100)
Weather_Imp=Weather_Imp_t
Weather_Imp=cbind(Location,Weather_Imp)
temp_weather_imp=Weather_Imp
names(Weather_Imp)
library(caTools)
set.seed(123)
split = sample.split(Weather_Imp1$RainTomorrow, SplitRatio = 0.75)
training_set = subset(Weather_Imp1, split == TRUE)
test_set = subset(Weather_Imp1, split == FALSE)
names(test_set)
#Scaling the datasets
training_set_sc=training_set[,50:55] %>%
mutate_if(is.numeric, scale)
test_set_sc=test_set[,50:55] %>%
mutate_if(is.numeric, scale)
training_set=cbind(training_set[1:49],training_set_sc,training_set[56:105])
str(training_set)
test_set=cbind(training_set[1:49],training_set_sc,training_set[56:105])
library(caTools)
set.seed(123)
split = sample.split(Weather_Imp1$RainTomorrow, SplitRatio = 0.75)
training_set = subset(Weather_Imp1, split == TRUE)
test_set = subset(Weather_Imp1, split == FALSE)
names(test_set)
#Scaling the datasets
training_set_sc=training_set[,50:55] %>%
mutate_if(is.numeric, scale)
test_set_sc=test_set[,50:55] %>%
mutate_if(is.numeric, scale)
training_set=cbind(training_set[1:49],training_set_sc,training_set[56:105])
str(training_set)
test_set=cbind(training_set[1:49],training_set_sc,training_set[56:105])
data <- read.csv("data.csv")
#POST-HOC TEST
#tukeyhsd()
TukeyHSD(aov.out)
PlantGrowth
###There is a difference, but where does this difference lie? Post Hoc test:
aov.out <- aov(lm.out) # we can ask for the corresponding ANOVA table
# instead of running an ANOVA with aov(), we will run a linear regression with lm()
lm.out = with(PlantGrowth, lm(weight ~ group))
summary(lm.out)
###There is a difference, but where does this difference lie? Post Hoc test:
aov.out <- aov(lm.out) # we can ask for the corresponding ANOVA table
TukeyHSD(lm.out)
getwd()
setwd("..")
setwd("ucuncu_sinif")
setwd("wm")
setwd("project")
wikizero <- read.csv("wikizero.csv")
blist <- read.csv("blist.csv")
View(blist)
View(wikizero)
wikizero$Species <- wikizero$Breed
wikizero <- wikizero[,-(1)]
wikizero <- wikizero[,-(1)]
library("dplyr", lib.loc="~/R/win-library/3.5")
aggregate(. ~ Species, rbind(wikizero,blist))
aggregate(. ~ Species, rbind(wikizero,blist))
d3 <- rbind(wikizero,blist)
merge(wikizero,blist,by="Species")
x <- merge(wikizero,blist,by="Species")
View(x)
wikiblist <- merge(wikizero,blist,by="Species")
rm(x)
View(wikiblist)
#activity level calm
url <- 'https://www.akc.org/dog-breeds/page/2/?activity_level%5B0%5D=calm'
webpage <- read_html(url)
library("rvest", lib.loc="~/R/win-library/3.5")
webpage <- read_html(url)
class(webpage)
temp <- html_nodes(webpage,'.f-25')
temp_data <- html_text(temp)
View(temp_data)
webpage2 <- read_html(url2)
url2 <- 'https://www.akc.org/dog-breeds/?activity_level%5B%5D=calm'
webpage2 <- read_html(url2)
temp <- html_nodes(webpage2,'.f-25')
temp_data <- html_text(temp)
View(temp_data)
t <- html_nodes(webpage,'.f-25')
t_data <- html_text(t)
View(temp_data)
View(t)
View(t_data)
temp <- html_nodes(webpage2,'.f-25')
temp_data <- html_text(temp)
View(temp_data)
calm <- merge(t_data,temp_data)
View(calm)
url3 <- 'https://www.akc.org/dog-breeds/?activity_level%5B%5D=regular-exercise'
webpage3 <- read.html(url3)
webpage3 <- read_html(url3)
reg <- html_nodes(webpage3,'.f-25')
reg_data <- html_text(reg)
View(reg_data)
url4 <- 'https://www.akc.org/dog-breeds/page/2/?activity_level%5B0%5D=regular-exercise'
webpage4 <- read_html(url4)
reg2 <- html_nodes(webpage4,'.f-25')
re_data <- html_text(reg2)
View(re_data)
write.csv(wikiblist, file = "wikiblist.csv")
wikiblist <- read.csv("wikiblist.csv")
View(wikiblist)
wikiblist <- wikiblist[,-(1)]
#wikiblist <- merge(wikizero,blist,by="Species")
sum(is.na(wikiblist))
levels(wikiblist$Activity.Level)
wikiblist$Activity.Level == "Calm" <- wikiblist$Activity.Level == "calm"
rm(wikiblist)
wikiblist <- read.csv("wikiblist.csv")
levels(wikiblist$Activity.Level)
#wikiblist <- merge(wikizero,blist,by="Species")
sum(is.na(wikiblist))
url <- 'https://www.pets4homes.co.uk/dog-breeds/?children%5B0%5D=5&sort=mostpopular'
webpage <- read_html(url)
class(webpage2)
class(webpage)
#scrap temperament
good1 <- html_nodes(webpage,'.title a')
good1_data <- html_text(good1)
url <- 'https://www.pets4homes.co.uk/dog-breeds/?page=2&children%5B0%5D=5&sort=mostpopular'
webpage <- read_html(url)
#scrap temperament
good2 <- html_nodes(webpage,'.title a')
good2_data <- html_text(good2)
url <- 'https://www.pets4homes.co.uk/dog-breeds/?page=3&children%5B0%5D=5&sort=mostpopular'
webpage <- read_html(url)
#scrap temperament
good3 <- html_nodes(webpage,'.title a')
good3_data <- html_text(good3)
url <- 'hhttps://www.pets4homes.co.uk/dog-breeds/?page=4&children%5B0%5D=5&sort=mostpopular'
webpage <- read_html(url)
#scrap temperament
good4 <- html_nodes(webpage,'.title a')
good4_data <- html_text(good4)
url <- 'https://www.pets4homes.co.uk/dog-breeds/?page=4&children%5B0%5D=5&sort=mostpopular'
webpage <- read_html(url)
url <- 'https://www.pets4homes.co.uk/dog-breeds/?page=4&children%5B0%5D=5&sort=mostpopular'
webpage <- read_html(url)
good4 <- html_nodes(webpage,'.title a')
good4_data <- html_text(good4)
total <- rbind(good1,good2,good3,good4)
View(total)
View(total)
total <- append(good1,good2,good3,good4)
total <- append(good1,good2,good3)
x <- append(good1,good2,good3)
merge.list(good1,good2,good3,good4)
library("readr", lib.loc="~/R/win-library/3.5")
library("tibble", lib.loc="~/R/win-library/3.5")
merge.list(good1,good2,good3,good4)
combine(good1,good2,good3,good4)
x <- combine(good1,good2,good3,good4)
View(x)
data.frame(x)
View(total)
View(x)
data.frame <- y
y <- data.frame
rep("Yes",92)
a <- rep("Yes",92)
merge(a,x)
combine(a,x)
a <- as.list(a)
combine(a,x)
ax <- combine(a,x)
View(ax)
ax <- merge(a,x)
do.call(rbind.data.frame, Map('c', a,x))
axx <- data.frame( Species = a,
Temperament = x)
#scrap species
good4 <- html_nodes(webpage,'.title a')
good4_data <- html_text(good4)
axx <- data.frame( Species = good4_data,
Temperament = x)
axx <- data.frame( Species = good4_data,
Temperament = a)
View(axx)
axx <- data.frame( Species = good3_data,Temperament = a)
View(axx)
rm(axx)
rm(ax)
rm(a)
rm(x)
rm(total)
yes <- rep("Yes",92)
one <- data.frame( Species = good1_data,Good_With_Children = yes)
species <- combine(good1_data,good2_data,good3_data,good4_data)
one <- data.frame( Species = species,Good_With_Children = yes)
View(one)
GWC <- data.frame( Species = species,Good_With_Children = yes)
rm(one)
View(GWC)
View(wikiblist)
View(GWC)
wikiblistgwc <- merge(wikiblist,GWC,by="Species")
View(wikiblistgwc)
rm(wikiblistgwc)
#no
url2 <- 'https://www.pets4homes.co.uk/dog-breeds/?children%5B0%5D=1&children%5B1%5D=2&sort=mostpopular'
webpage2 <- read_html(url2)
bad <- html_nodes(webpage2,'.title a')
bad_data <- html_text(bad)
good <- combine(good1_data,good2_data,good3_data,good4_data)
children <- combine(good, bad_data)
answer <- rep("No",29)
c <- data.frame(tur = bad ,cvp = answer)
c <- data.frame(tur = bad_data ,cvp = answer)
View(c)
yesler <- data.frame(Species = species, Good_With_Children = yes)
View(yesler)
no <- rep("No",29)
nolar <- data.frame(Species = bad_data ,Good_With_Children = no )
View(nolar)
View(yesler)
rm(bad)
rm(c)
rm(good)
rm(good1)
rm(good2)
rm(good3)
rm(good4)
rm(GWC)
rm(webpage)
rm(webpage2)
children <- merge(yesler,nolar)
View(children)
children <- merge(yesler,nolariby=c("Good_With_Children"))
children <- merge(yesler,nolariby=c("Species","Good_With_Children"))
children <- merge(yesler,nolar,
by=c("Species","Good_With_Children"))
b$b <- NA
children$b <- NA
nolar <- data.frame(Species = bad_data&good ,Good_With_Children = no )
good <- combine(good1_data,good2_data,good3_data,good4_data)
nolar <- data.frame(Species = bad_data&good ,Good_With_Children = no )
write.csv(nolar,"no.csv")
write.csv(yesler, "yes.csv")
rm(children)
gwc <- read.csv("gwc.csv")
getwd()
setwd(gwc)
setwd("gwc")
gwc <- read.csv("gwc.csv")
View(gwc)
gwc <- gwc[,-(1)]
View(wikiblist)
wikiblistgwc <- merge(gwc,wikiblist,by="Species")
View(wikiblistgwc)
gwc <- gwc[,-(3)]
write.csv(wikiblistgwc, "wikiblistgwc.csv")
url3 <- 'https://www.dogspot.in/kid-friendly-dog-breeds/'
webpage3 <- read_html(url3)
good2 <- html_nodes(webpage3,'productFilter h3')
good22_data <- html_text(good2)
good <- combine(good1_data,good2_data,good3_data,good4_data,good22_data)
good2 <- html_nodes(webpage3,'#productFilter h3')
good22_data <- html_text(good2)
good <- combine(good1_data,good2_data,good3_data,good4_data,good22_data)
yes <- rep("Yes",139)
yesler <- data.frame(Species = good, Good_With_Children = yes)
View(yesler)
write.csv(yesler, "yes.csv")
wikiblistgwc <- merge(gwc,wikiblist,by="Species")
View(wikiblistgwc)
View(gwc)
write.csv(wikiblistgwc, "wikiblistgwc.csv")
View(wikiblistgwc)
data <- read.csv("wikiblistgwclife")
getwd()
setwd("..")
getwd()
data <- read.csv("wikiblistgwclife")
data <- read.csv("wikiblistgwclife.csv")
View(data)
getwd()
data <- read.csv("wikiblistgwclife.csv")
View(data)
levels(data)
levels(data$Good_With_Children)
levels(data$Hypoallergenic)
levels(data$Activity.Level)
levels(data$Life.Expectancy)
levels(data$Size)
sum(is.na(data))
View(data)
getwd()
wikiblist <- read.csv("wikiblist.csv")
blist <- read.csv("blist.csv")
setwd("blists")
setwd("blist")
setwd("blistler")
blist <- read.csv("blist.csv")
setwd("..")
setwd("wikizero")
wikizero <- read.csv("wikizero.csv")
View(blist)
View(wikizero)
View(wikiblist)
View(data)
View(blist)
wikizero <- wikizero[,-(1)]
wikiblist <- wikiblist[,-(1)]
View(data)
